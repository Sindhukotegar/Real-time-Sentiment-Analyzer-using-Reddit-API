!pip3 install praw
import re
pip install pyspark
#pip install praw #Jupyter
#conda install -c conda-forge praw #Anaconda
import praw
# Log In to App:
reddit = praw.Reddit(client_id='***', client_secret='***', user_agent='Data Scraping')
subs = reddit.subreddit('datascience').hot(limit=10)

for submission in subs:
    print(submission.title)
subs = reddit.subreddit('datascience').top('year')

for submission in subs:
    print(submission.title,',',submission.num_comments,',',submission.score)
for submission in reddit.subreddit("datascience").top('year'):
    print(submission.title,',',submission.num_comments,',',submission.score)
import pandas as pd
pd.set_option('max_colwidth', None)
df = []

subreddit = reddit.subreddit('datascience')

for post in subreddit.hot(limit=1000):
    df.append([post.title, post.score, post.url, post.num_comments, post.selftext])

df = pd.DataFrame(df,columns=['title', 'score', 'url', 'num_comments', 'body'])
df
df5 = df.drop("url", axis=1)
df5
pip install vaderSentiment
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
#from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Initialize Spark session
spark = SparkSession.builder \
    .appName("SentimentAnalysis") \
    .getOrCreate()

# Initialize VADER sentiment analyzer
analyzer = SentimentIntensityAnalyzer()


# Define function for sentiment analysis
def analyze_sentiment(text):
    sentiment_score = analyzer.polarity_scores(text)
    if sentiment_score['compound'] >= 0.05:
        return "Positive"
    elif sentiment_score['compound'] <= -0.05:
        return "Negative"
    else:
        return "Neutral"


# Pre-processing steps
df2 = df1.dropna() # Remove rows with missing text in the "body" column

# Register sentiment analysis function as a UDF
sentiment_udf = udf(analyze_sentiment, StringType())

# Create a new column
df2["posts_with_sentiment"] = df2["body"].apply(lambda text: analyzer.polarity_scores(text)["compound"])
#  can now access the sentiment score in the new column

#df.sort_values(by=['score'], inplace=True, ascending=False)
df2[['title', 'score','num_comments','body',"posts_with_sentiment"]].head(10)

#print(df2.head())

# Stop Spark session
spark.stop()
import pandas as pd

def categorize_sentiment(score):
    if score >= 0.05:
        return 'positive'
    elif score <= -0.05:
        return 'negative'
    else:
        return 'neutral'

# Apply the categorize_sentiment function to create a new column
df2['sentiment_category'] = df2['posts_with_sentiment'].apply(categorize_sentiment)
df2.head()

